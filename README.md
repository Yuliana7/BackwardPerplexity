# BackPerplexity
Investigate perplexity of LLM's when trained backward vs forward


Code used for the Natural Language experiments of the paper 'Arrows of Time in Large Langugage Models'